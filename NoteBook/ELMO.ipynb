{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k65jBGgapXHJ"
   },
   "source": [
    "# Using ELMO\n",
    "* Since it only supports TF1.x now, we need to shift to old version\n",
    "* The coding style will be quite different\n",
    "* Most the code are from this [reference](https://github.com/strongio/keras-elmo/blob/master/Elmo%20Keras.ipynb)\n",
    "* In tf1.x, we need to create **session** and establish the structure then executing all the code *inside* this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "-xKoyoXZVVIp",
    "outputId": "e5aea07c-0b7b-47fb-b53a-c006c6bdeaf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
      "You set: `1.x  # use TF1 here`. This will be interpreted as: `1.x`.\n",
      "\n",
      "\n",
      "TensorFlow 1.x selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 1.x  # use TF1 here\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from keras import backend as K\n",
    "import keras.layers as layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.engine import Layer\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__) # confirm version\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aY3K2RkFaI7u"
   },
   "source": [
    "## Load the data\n",
    "* Stemming might not be a good choice since the model cares about tense and singular/plural of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mk1vzE3zdRA5"
   },
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "BATCH_SIZE = 128\n",
    "EMBED_SIZE = 1024\n",
    "MAX_LENGTH = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aIhx7yyMaIGo"
   },
   "outputs": [],
   "source": [
    "DATA = pd.read_csv('train_tokenize_nostem.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H-bDzXAjLNgR"
   },
   "source": [
    "If we need to handle the tokenization by ourselves...\n",
    "we don't need that in ELMO, but I still provided here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eerl-e1Pc8KW"
   },
   "outputs": [],
   "source": [
    "# Convert str into list, some detail when we read in the list from csv file\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from ast import literal_eval\n",
    "print(type(DATA.loc[0,'TOKEN']))\n",
    "\n",
    "# convert str back to correct list type, this happens since we store the file into .csv\n",
    "DATA['TOKEN'] = DATA['TOKEN'].apply(literal_eval)\n",
    "print(type(DATA.loc[0,'TOKEN']))\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# padding to MAX_LENGTH (computer only support rectangular(uniform) object)\n",
    "for row in DATA['TOKEN']:\n",
    "  if len(row) < MAX_LENGTH:\n",
    "    row.extend(['' for _ in range(MAX_LENGTH-len(row))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "OAJyQ5vVcv-M",
    "outputId": "1a49424a-8841-4de0-8865-2ae6df599b23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA_train.shape:  (35150, 13)\n",
      "DATA_val.shape:  (11717, 13)\n"
     ]
    }
   ],
   "source": [
    "#split to train and val\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "DATA_train, DATA_val= train_test_split(DATA, test_size=0.25)\n",
    "print('DATA_train.shape: ', DATA_train.shape)\n",
    "print('DATA_val.shape: ', DATA_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "K2M07kHZc4Wn",
    "outputId": "1a44f9a7-5918-4a8c-fcf7-bfa1b2cc6f04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35150, 1) (11717, 1)\n",
      "(35150, 2) (11717, 2)\n",
      "(35150, 6) (11717, 6)\n"
     ]
    }
   ],
   "source": [
    "# Select the correct column we need\n",
    "TOKEN_train = DATA_train.loc[:,'Sentences']\n",
    "# TOKEN_train = [' '.join(t.split()[0:MAX_LENGTH]) for t in TOKEN_train]\n",
    "TOKEN_train = np.array(TOKEN_train, dtype=object)[:, np.newaxis]\n",
    "\n",
    "POSITION_train = DATA_train.loc[:,['POSITION','TOTAL_LEN']].to_numpy()\n",
    "LABEL_train = DATA_train.loc[:,'BACKGROUND':'OTHERS'].to_numpy()\n",
    "\n",
    "TOKEN_val = DATA_val.loc[:,'Sentences']\n",
    "# TOKEN_val = [' '.join(t.split()[0:MAX_LENGTH]) for t in TOKEN_val]\n",
    "TOKEN_val = np.array(TOKEN_val, dtype=object)[:, np.newaxis]\n",
    "\n",
    "POSITION_val = DATA_val.loc[:,['POSITION','TOTAL_LEN']].to_numpy()\n",
    "LABEL_val = DATA_val.loc[:,'BACKGROUND':'OTHERS'].to_numpy()\n",
    "\n",
    "print(TOKEN_train.shape, TOKEN_val.shape)\n",
    "print(POSITION_train.shape, POSITION_val.shape)\n",
    "print(LABEL_train.shape, LABEL_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "dUsMSScSJvZi",
    "outputId": "190317ce-cc02-4ca7-e901-3efd507ed720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['testing in continuous integration involves test case prioritization selection and execution at each cycle .']\n",
      " ['we propose a new task for grounding language in this environment given a natural language command e .g . click on the second article choose the correct element on the web page e .g . a hyperlink or text box .']]\n",
      "[['our method improved results across all languages .']\n",
      " ['the proposed algorithm relies on abductive-inductive learning and comprises a scalable clause refinement methodology based on a compressive summarization of clause coverage in a stream of examples .']]\n",
      "[[1 6]\n",
      " [2 7]]\n"
     ]
    }
   ],
   "source": [
    "# some example \n",
    "print(TOKEN_train[0:2])\n",
    "print(TOKEN_val[0:2])\n",
    "print(POSITION_train[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lqZCyciQaFG7"
   },
   "source": [
    "## Load the model (testing)\n",
    "Elmo care about \n",
    "  * Punctuation\n",
    "  * Tense\n",
    "  * plural/single\n",
    "  * upper/lower case (https://github.com/tensorflow/hub/issues/215)\n",
    "  * Also, accept numbers input (in str form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7P3XNGZKd3qc"
   },
   "outputs": [],
   "source": [
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/3\",trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7wK0fnXIhDbp",
    "outputId": "ecd932ce-52ae-474c-861e-359f0e62313d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "embeddings = elmo(['a.k.a.', 'e.g.'],\n",
    "    signature=\"default\", as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "QHEm5UsOhx6d",
    "outputId": "e10f9646-4738-468f-87eb-91d9af03b92e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1781: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "##we can load the model in two method, actually I haven't figure out their difference\n",
    "# elmo = hub.KerasLayer(\"https://tfhub.dev/google/elmo/3\",trainable=True, signature=\"default\",output_key=\"elmo\")\n",
    "\n",
    "##test hub.KerasLayer, no need to specified the signature and output\n",
    "# embeddings = elmo(K.squeeze(K.cast(TOKEN_train[0:2], tf.string), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "B9yVXQb2nlKF",
    "outputId": "6d1a3f7a-2dd1-4933-c0be-1800642944a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1, 1024)\n",
      "[[[-0.37405166 -0.5001462   0.13569671 ... -0.64118576  0.5069206\n",
      "   -0.63167405]]\n",
      "\n",
      " [[-0.51674646  0.02469666 -0.22523886 ... -0.32503623 -0.00995439\n",
      "   -0.07440427]]]\n"
     ]
    }
   ],
   "source": [
    "# run and check the result\n",
    "sess.run(tf.global_variables_initializer())\n",
    "embedding = sess.run(embeddings)\n",
    "print(embedding.shape)\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "GYGUSNF7gNZK",
    "outputId": "ebfb214a-36a2-4706-fd26-56eb4ebe4466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# test with our data\n",
    "embeddings = elmo(K.squeeze(K.cast(TOKEN_train[0:2], tf.string), axis=1),\n",
    "    signature=\"default\", as_dict=True)[\"elmo\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8lnNuVuigUo3",
    "outputId": "fcc5a27a-9e2a-43c3-c286-1cf43610730c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 19, 1024)\n"
     ]
    }
   ],
   "source": [
    "# run and check the result\n",
    "sess.run(tf.global_variables_initializer())\n",
    "embedding = sess.run(embeddings)\n",
    "print(embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yf8GD1qnbkjP"
   },
   "source": [
    "## Define the model\n",
    "Create a custom layer that allows us to update weights (lambda layers do not have trainable parameters!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9A1gmVdStLwX"
   },
   "outputs": [],
   "source": [
    "#Everytime you want to try some new thing (like change the model structure), you need to clear the session first\n",
    "#to prevent something inside the graph are left and affect the model or the result\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mQ9e4qL1r3EO"
   },
   "outputs": [],
   "source": [
    "class ElmoEmbeddingLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "      self.dimensions = 1024\n",
    "      self.trainable=True\n",
    "      super(ElmoEmbeddingLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "      self.elmo = hub.Module('https://tfhub.dev/google/elmo/3', trainable=self.trainable,\n",
    "                              name=\"{}_module\".format(self.name))\n",
    "\n",
    "      self.trainable_weights += tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\n",
    "      super(ElmoEmbeddingLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "      result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1),\n",
    "                    as_dict=True,\n",
    "                    signature='default',\n",
    "                    )['elmo']\n",
    "      return result\n",
    "\n",
    "    # def compute_mask(self, inputs, mask=None):  #Performance increase without masking, don't know the reason yet\n",
    "    #   return K.not_equal(inputs, '')\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "      return (input_shape[0], None, self.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PHBl8bv1tmJ4"
   },
   "source": [
    "If we don't need to fine tune the weight in ELMO, we can just use the LambdaLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pT08l0K7tUS3"
   },
   "outputs": [],
   "source": [
    "def ELMOWordsEmbedding(tokens_input):\n",
    "  result = elmo(\n",
    "      K.squeeze(K.cast(tokens_input, tf.string), axis=1),\n",
    "      signature=\"default\",\n",
    "      as_dict=True)[\"elmo\"]\n",
    "  return result\n",
    "\n",
    "def compute_mask(tokens_input, mask=None):\n",
    "  return  K.not_equal(K.cast(tokens_input, tf.string),'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ymrvTRWUhsMn"
   },
   "source": [
    "Valuation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nPpzH8Nybopj"
   },
   "outputs": [],
   "source": [
    "# Function to calculate F1_score\n",
    "def F1_score(y_true, y_pred):\n",
    "  DTYPE = tf.float32\n",
    "  THRESHOLD = 0.5\n",
    "\n",
    "  y_pred = tf.cast(y_pred > THRESHOLD, DTYPE) \n",
    "\n",
    "  true_positives = tf.math.count_nonzero(tf.math.logical_and(tf.math.equal(y_pred,1.0), tf.math.equal(y_true,1.0)), axis=0)\n",
    "  false_positives = tf.math.count_nonzero(tf.math.logical_and(tf.math.equal(y_pred,1.0), tf.math.equal(y_true,0.0)), axis=0)\n",
    "  false_negatives = tf.math.count_nonzero(tf.math.logical_and(tf.math.equal(y_pred,0.0), tf.math.equal(y_true,1.0)), axis=0)\n",
    "\n",
    "  TP = tf.math.reduce_sum(tf.cast(true_positives, DTYPE), axis=0)\n",
    "  FP = tf.math.reduce_sum(tf.cast(false_positives, DTYPE), axis=0)\n",
    "  FN = tf.math.reduce_sum(tf.cast(false_negatives, DTYPE), axis=0)\n",
    "\n",
    "  precision = tf.math.divide_no_nan(TP, TP+FP)\n",
    "  recall = tf.math.divide_no_nan(TP, TP+FN)\n",
    "\n",
    "  F1 = tf.math.divide_no_nan(2 * (precision * recall) , (precision + recall))\n",
    "  return F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FeRZOvHsqRCF",
    "outputId": "423e841c-8c2d-4d1e-9df1-a028ba2a01a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Text_input (InputLayer)         (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ElmoEmbed (ElmoEmbeddingLayer)  (None, None, 1024)   4           Text_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "BiGRU (Bidirectional)           (None, 512)          1967616     ElmoEmbed[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Sentence_position (InputLayer)  (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Merge (Concatenate)             (None, 514)          0           BiGRU[0][0]                      \n",
      "                                                                 Sentence_position[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 6)            3090        Merge[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,970,710\n",
      "Trainable params: 1,970,710\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to build model\n",
    "def build_model(): \n",
    "  input_text = layers.Input(shape=(1,), name='Text_input', dtype=tf.string)\n",
    "  input_position = layers.Input(shape=(2,), name='Sentence_position', dtype=tf.float32)\n",
    "\n",
    "  # Using Lambda layer - this will result in a fixed ELMO embedding layer\n",
    "  #embedding = layers.Lambda(ELMOWordsEmbedding, output_shape=(None, 1024), mask=compute_mask)(input_text)\n",
    "  # ELMO embedding with trainable weight\n",
    "  embedding = ElmoEmbeddingLayer(name=\"ElmoEmbed\")(input_text)\n",
    "  GRU = layers.Bidirectional(layers.GRU(256, dropout=0.5, return_sequences=False), name='BiGRU')(embedding)\n",
    "\n",
    "  concat = layers.concatenate([GRU, input_position], name='Merge')\n",
    "  pred = layers.Dense(6, activation='sigmoid')(concat)\n",
    "\n",
    "  model = Model(inputs=[input_text, input_position], outputs=pred)\n",
    "  adam = Adam(lr=0.001)\n",
    "\n",
    "  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=[F1_score])\n",
    "  model.summary()\n",
    "  \n",
    "  return model\n",
    "\n",
    "model = build_model()\n",
    "# save the weight for later retraining the whole module\n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wl4XZrSMb9le"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "qp2yoU3Qb5tu",
    "outputId": "cf705b85-7a77-4a9b-c631-2819452f21ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35150 samples, validate on 11717 samples\n",
      "Epoch 1/3\n",
      "35150/35150 [==============================] - 256s 7ms/step - loss: 0.3405 - F1_score: 0.5359 - val_loss: 0.3051 - val_F1_score: 0.6026\n",
      "Epoch 2/3\n",
      "35150/35150 [==============================] - 238s 7ms/step - loss: 0.3010 - F1_score: 0.6163 - val_loss: 0.2933 - val_F1_score: 0.6365\n",
      "Epoch 3/3\n",
      "35150/35150 [==============================] - 238s 7ms/step - loss: 0.2868 - F1_score: 0.6409 - val_loss: 0.2938 - val_F1_score: 0.6461\n"
     ]
    }
   ],
   "source": [
    "# Monitor the performance\n",
    "from keras.callbacks import EarlyStopping\n",
    "early_stopping = EarlyStopping(monitor='val_F1_score', patience=3, mode='max')\n",
    "\n",
    "history = model.fit([TOKEN_train,POSITION_train], LABEL_train,\n",
    "          validation_data=([TOKEN_val,POSITION_val], LABEL_val),\n",
    "          epochs=15, batch_size=BATCH_SIZE,\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u0v7nT5OcQvd"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "xpClCcc0cSHQ",
    "outputId": "4a59e26e-ff5b-4883-8a0d-bbcf04bb748b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11717, 6)\n",
      "[[0.00588551 0.01260564 0.03800076 0.92279714 0.131506   0.00637618]\n",
      " [0.48207766 0.16796616 0.37107742 0.07503074 0.07100105 0.01586792]\n",
      " [0.7165873  0.04636222 0.06908572 0.05316025 0.01516324 0.00488138]\n",
      " [0.07452565 0.06215289 0.6697212  0.34838733 0.03677234 0.00340721]]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict([TOKEN_val,POSITION_val])\n",
    "\n",
    "print(result.shape)\n",
    "print(result[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "7Z4LBIV9cUa6",
    "outputId": "d893e794-c30f-4352-fd35-67f002fe9564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11717, 6)\n",
      "(11717, 6)\n",
      "0.6473844105039744\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "greater = (result>=0.5).astype(int)\n",
    "print(LABEL_val.shape)\n",
    "print(greater.shape)\n",
    "print(f1_score(LABEL_val, greater, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gDtP9_HjcZ2x"
   },
   "source": [
    "### Refit on the whole data with around 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCYeXdyLcSa5"
   },
   "outputs": [],
   "source": [
    "ALL_train = DATA.loc[:,'Sentences']\n",
    "ALL_train = np.array(ALL_train, dtype=object)[:, np.newaxis]\n",
    "ALL_POSITION_train = DATA.loc[:,['POSITION','TOTAL_LEN']].to_numpy()\n",
    "\n",
    "ALL_LABEL = DATA.loc[:,'BACKGROUND':'OTHERS'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "5EtGXvcndQoh",
    "outputId": "7f3f2ac5-2956-481b-e89a-8c154754e46b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46867, 1)\n",
      "(46867, 2)\n",
      "(46867, 6)\n"
     ]
    }
   ],
   "source": [
    "print(ALL_train.shape)\n",
    "print(ALL_POSITION_train.shape)\n",
    "print(ALL_LABEL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "bHRjo4I1cfkV",
    "outputId": "006c044b-8304-4e3d-cfd7-6e05fdef58b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "46867/46867 [==============================] - 245s 5ms/step - loss: 0.3374 - F1_score: 0.5400\n",
      "Epoch 2/5\n",
      "46867/46867 [==============================] - 245s 5ms/step - loss: 0.2998 - F1_score: 0.6170\n",
      "Epoch 3/5\n",
      "46867/46867 [==============================] - 245s 5ms/step - loss: 0.2875 - F1_score: 0.6396\n",
      "Epoch 4/5\n",
      "46867/46867 [==============================] - 244s 5ms/step - loss: 0.2799 - F1_score: 0.6540\n",
      "Epoch 5/5\n",
      "46867/46867 [==============================] - 243s 5ms/step - loss: 0.2727 - F1_score: 0.6640\n"
     ]
    }
   ],
   "source": [
    "# reload the model weight\n",
    "model.set_weights(weights)\n",
    "# train with best epoch = 5\n",
    "history = model.fit([ALL_train,ALL_POSITION_train], ALL_LABEL,\n",
    "          epochs=5, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RGEzeU3OchIK"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "O76lyJPqciuS",
    "outputId": "56ed0544-1c9c-4814-e72f-0fac2a921cbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131166, 1)\n",
      "(131166, 2)\n"
     ]
    }
   ],
   "source": [
    "TEST_DATA = pd.read_csv('test_tokenize_nostem.csv')\n",
    "test = TEST_DATA.loc[:,'Sentences']\n",
    "test = np.array(test, dtype=object)[:, np.newaxis]\n",
    "POSITION_test = TEST_DATA.loc[:,['POSITION','TOTAL_LEN']].to_numpy()\n",
    "\n",
    "print(test.shape)\n",
    "print(POSITION_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "HqrrxkojMCy-",
    "outputId": "4fb212b5-130c-40dc-9163-5cfe50b84e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131166, 6)\n",
      "[[0.00370848 0.00314283 0.01640809 0.7887437  0.57728094 0.00105613]\n",
      " [0.9920742  0.02068135 0.01025519 0.00269032 0.00636393 0.00972047]\n",
      " [0.16082975 0.6936044  0.29678756 0.07848769 0.07863769 0.01464307]\n",
      " [0.02329394 0.14286119 0.21164942 0.43658984 0.16394943 0.08761445]]\n"
     ]
    }
   ],
   "source": [
    "TEST_RESULT = model.predict([test,POSITION_test])\n",
    "\n",
    "print(TEST_RESULT.shape)\n",
    "print(TEST_RESULT[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "WPwa2z4BMWCd",
    "outputId": "4a871a7e-00dc-4128-d45a-0ffa4c454ac3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>OBJECTIVES</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>RESULTS</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.981662</td>\n",
       "      <td>0.046026</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.007027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.863804</td>\n",
       "      <td>0.289979</td>\n",
       "      <td>0.028492</td>\n",
       "      <td>0.018001</td>\n",
       "      <td>0.036511</td>\n",
       "      <td>0.005382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.174576</td>\n",
       "      <td>0.405271</td>\n",
       "      <td>0.710111</td>\n",
       "      <td>0.044601</td>\n",
       "      <td>0.054216</td>\n",
       "      <td>0.005105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013194</td>\n",
       "      <td>0.735298</td>\n",
       "      <td>0.343895</td>\n",
       "      <td>0.105276</td>\n",
       "      <td>0.062246</td>\n",
       "      <td>0.001103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.007108</td>\n",
       "      <td>0.010520</td>\n",
       "      <td>0.109356</td>\n",
       "      <td>0.668826</td>\n",
       "      <td>0.203339</td>\n",
       "      <td>0.023432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BACKGROUND  OBJECTIVES   METHODS   RESULTS  CONCLUSIONS    OTHERS\n",
       "0    0.981662    0.046026  0.010622  0.000734     0.003867  0.007027\n",
       "1    0.863804    0.289979  0.028492  0.018001     0.036511  0.005382\n",
       "2    0.174576    0.405271  0.710111  0.044601     0.054216  0.005105\n",
       "3    0.013194    0.735298  0.343895  0.105276     0.062246  0.001103\n",
       "4    0.007108    0.010520  0.109356  0.668826     0.203339  0.023432"
      ]
     },
     "execution_count": 58,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULT = pd.DataFrame(TEST_RESULT, columns=DATA.loc[:,'BACKGROUND':'OTHERS'].columns)\n",
    "RESULT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tqs0GTM2MktR"
   },
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "RESULT.to_csv('test_result'.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ELMO.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
