{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qRzJESWHFISd"
   },
   "source": [
    "# Bidirectional RNN\n",
    "* Using several kind of pretrained embedding from TF-hub\n",
    "  * nnlm-en-dim128\n",
    "  * gnews-swivel-20dim-with-oov\n",
    "  * Wiki-words-500\n",
    "  * Wiki-words-250\n",
    "* Tokenize the sentences\n",
    "* Embed **each** words into vector\n",
    "* Using Bidirectional RNN to extract the summary of the sentences\n",
    "* Classify using a Fully connected layer\n",
    "* We need to patch the sentences to same length, so the model can process them as a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "aKL5GwgVFDxb",
    "outputId": "68f3ec9b-3ff2-4f03-a9ad-916b6fd9124c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`%tensorflow_version` only switches the major version: `1.x` or `2.x`.\n",
      "You set: `2.x  # use TF2.0`. This will be interpreted as: `2.x`.\n",
      "\n",
      "\n",
      "TensorFlow is already loaded. Please restart the runtime to change versions.\n",
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x  # use TF2.0\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__) # confirm version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n8X07K3AVofc"
   },
   "source": [
    "## Load data\n",
    "* Using Tokenize data\n",
    "* Stemming or not?  **-> Result: no stemming will yield better result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpLD01V_Vurp"
   },
   "outputs": [],
   "source": [
    "STEMMING = False #@param {type:\"boolean\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V3O4xI-EV0vv",
    "outputId": "59ab571c-0150-4cd7-e407-054fd4913214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "if STEMMING:\n",
    "  DATA = pd.read_csv('train_tokenize.csv')\n",
    "else:\n",
    "  DATA = pd.read_csv('train_tokenize_nostem.csv')\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "from ast import literal_eval\n",
    "print(type(DATA.loc[0,'TOKEN']))\n",
    "\n",
    "# convert str back to correct list type, this happens since we store the file into .csv\n",
    "DATA['TOKEN'] = DATA['TOKEN'].apply(literal_eval)\n",
    "print(type(DATA.loc[0,'TOKEN']))\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LBx-JIp6GOot"
   },
   "source": [
    "If the LENGTH==1 sentences are also desired in training, we should check the empty sentences and replace it as a **\\<UNK\\>** token in case whole sentence will be mask out (since we use empty string to mask the sentence) and cause error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oOMb3k_fWyb-",
    "outputId": "05faf494-bc2c-4383-dc1c-7d28bfaa6a70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46867,)\n",
      "(46867, 6)\n"
     ]
    }
   ],
   "source": [
    "# TRAIN = DATA.loc[DATA['LENGTH']>1,'TOKEN']\n",
    "# LABEL = DATA.loc[DATA['LENGTH']>1,'BACKGROUND':'OTHERS'] \n",
    "\n",
    "TRAIN = DATA.loc[:,'TOKEN']\n",
    "LABEL = DATA.loc[:,'BACKGROUND':'OTHERS'] \n",
    "\n",
    "print(TRAIN.shape)\n",
    "print(LABEL.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vH90O8l9DZZw"
   },
   "outputs": [],
   "source": [
    "#padding to MAX_LENGTH\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "for row in TRAIN:\n",
    "  if len(row) < MAX_LENGTH:\n",
    "    row.extend(['' for _ in range(MAX_LENGTH-len(row))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "q9HrkvplMr0Y",
    "outputId": "1f348c1b-a03e-4165-e3d5-5d7fb4e6d3e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n",
      "256\n",
      "['rapid', 'popularity', 'of', 'internet', 'of', 'things', 'and', 'cloud', 'computing', 'permits', 'neuroscientists', 'to', 'collect', 'multilevel', 'and', 'multichannel', 'brain', 'data', 'to', 'better', 'understand', 'brain', 'functions', 'diagnose', 'diseases', 'and', 'devise', 'treatments', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# check \n",
    "print(len(TRAIN[0]))\n",
    "print(len(TRAIN[1000]))\n",
    "print(TRAIN[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "PvovKDo1W2z5",
    "outputId": "9ed465e3-be43-4c0a-c037-09a4df13a5aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (35150,)\n",
      "y_train.shape:  (35150, 6)\n",
      "X_test.shape:  (11717,)\n",
      "y_test.shape:  (11717, 6)\n"
     ]
    }
   ],
   "source": [
    "#split to train and val\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(TRAIN, LABEL,  test_size=0.25)\n",
    "print('X_train.shape: ', X_train.shape)\n",
    "print('y_train.shape: ', Y_train.shape)\n",
    "print('X_test.shape: ', X_val.shape)\n",
    "print('y_test.shape: ', Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1uGq8qBW6a6"
   },
   "source": [
    "### create dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "tM1jjrZKXAqY"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512 #@param {type:\"slider\", min:64, max:1024, step:64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "anbu8zLgW-3J",
    "outputId": "844d4552-e9bd-4e65-a969-0b01171884e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: [b'we' b'introduce' b'a' b'multilayer' b'ground' b'model' b'for' b'the'\n",
      " b'recently-proposed' b'mom-so' b'method' b'suitable' b'to' b'accurately'\n",
      " b'predict' b'ground' b'return' b'effects' b'in' b'such' b'scenarios' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''\n",
      " b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b'' b''], Target: [0 0 1 0 0 0]\n",
      "--------------------------------------------------\n",
      "Features: [[b'we' b'introduce' b'a' ... b'' b'' b'']\n",
      " [b'this' b'paper' b'presents' ... b'' b'' b'']\n",
      " [b'for' b'depth' b'we' ... b'' b'' b'']\n",
      " [b'we' b'carry' b'out' ... b'' b'' b'']\n",
      " [b'to' b'develop' b'a' ... b'' b'' b'']], \n",
      "Target: [[0 0 1 0 0 0]\n",
      " [0 0 1 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [1 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train.values))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, Y_val.values))\n",
    "#investigate the dataset\n",
    "for feat, targ in train_dataset.take(1):\n",
    "  print ('Features: {}, Target: {}'.format(feat, targ))\n",
    "\n",
    "print ('--------------------------------------------------')\n",
    "# shuffle, set batch and set prefetch\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE)\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "# now it will take 1 batch out and the order is messed (only show 5 below)\n",
    "for feat, targ in train_dataset.take(1):\n",
    "  print ('Features: {}, \\nTarget: {}'.format(feat[0:5], targ[0:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DgcWHyB_QuV_"
   },
   "source": [
    "## Embed using pretrain Wiki-words-250/nnlm-128\n",
    "* [How-To-Embed-in-TensorFlow](https://github.com/FrancescoSaverioZuppichini/How-To-Embed-in-TensorFlow)\n",
    "* In **Wiki-words-250/500**, Unseen token will output as a whole 0 vector\n",
    "* **Wiki-words-250/500** no big performance different\n",
    "* **Wiki-words-250** can't embed punctuation\n",
    "* **NNLM** seems it is a network-like weight-based model, it can handle any input include punctuation (But I don't know whether it is a reasonable embediing or not)\n",
    "* Both of them care about the tense and singular/plural of the word, so *stemming* might not be a good choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8dlXp4vLpjSx"
   },
   "outputs": [],
   "source": [
    "EMBED_SIZE = 250 \n",
    "if EMBED_SIZE == 128:\n",
    "  Model_URL = \"https://tfhub.dev/google/nnlm-en-dim128/2\"\n",
    "elif EMBED_SIZE == 20:  \n",
    "  Model_URL = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim-with-oov/1\"\n",
    "elif EMBED_SIZE == 500: \n",
    "  Model_URL = \"https://tfhub.dev/google/Wiki-words-500/2\"\n",
    "else:\n",
    "  Model_URL = \"https://tfhub.dev/google/Wiki-words-250/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RBqxR-rJiHjv"
   },
   "outputs": [],
   "source": [
    "embed = hub.load(Model_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b7kmF4mQe5on"
   },
   "source": [
    "### Define a layer that can be used later in Keras\n",
    "we need to reshape the input tensor, since the pretrain embed layer only accept 1D input. It seems that this layer was originally designed to embed a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bAqcRzTVGnTO"
   },
   "outputs": [],
   "source": [
    "def WikiWordsEmbedding(x):\n",
    "  x = tf.reshape(tf.cast(x, tf.string), [-1])\n",
    "  result = embed(x)\n",
    "  return tf.reshape(result, [-1, MAX_LENGTH, EMBED_SIZE]) # reshape back to the Tensor we want\n",
    "\n",
    "def compute_mask(x,y):  # receive 2 argument but y is None (don't know why yet, but we don't need it)\n",
    "  return tf.math.not_equal(x,'')\n",
    "\n",
    "embed_layer = tf.keras.layers.Lambda(WikiWordsEmbedding, output_shape=(None,MAX_LENGTH,EMBED_SIZE), mask=compute_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "YrBT54nSNkSE",
    "outputId": "8b7fad51-c4c8-4059-b49d-8010b1cadd80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256,)\n",
      "(512, 256, 250)\n",
      "tf.Tensor(\n",
      "[[[-0.10056633 -0.01571468  0.04843812 ... -0.00983353 -0.014313\n",
      "   -0.06990035]\n",
      "  [-0.00509347  0.00251882  0.08547001 ... -0.01865194  0.08163237\n",
      "   -0.01506454]\n",
      "  [-0.04388279 -0.14637887 -0.02515217 ... -0.01614045 -0.00135054\n",
      "   -0.04300075]\n",
      "  ...\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]\n",
      "  [ 0.          0.          0.         ...  0.          0.\n",
      "    0.        ]]], shape=(1, 256, 250), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.10056633 -0.01571468  0.04843812 ... -0.00983353 -0.014313\n",
      "  -0.06990035]\n",
      " [-0.00509347  0.00251882  0.08547001 ... -0.01865194  0.08163237\n",
      "  -0.01506454]\n",
      " [-0.04388279 -0.14637887 -0.02515217 ... -0.01614045 -0.00135054\n",
      "  -0.04300075]\n",
      " ...\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]], shape=(256, 250), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# testing, check the shape and value wiil be the same after reshape\n",
    "for feat, targ in train_dataset.take(1):\n",
    "  print(feat[0].shape)\n",
    "  print(embed_layer(feat).shape)\n",
    "  print(embed_layer(feat[0]))\n",
    "  print(embed(feat[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pjf5r6dHMac9"
   },
   "source": [
    "## Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S_dg1NbaMcuE"
   },
   "outputs": [],
   "source": [
    "# Function to calculate F1_score\n",
    "def F1_score(y_true, y_pred):\n",
    "  DTYPE = tf.float32\n",
    "  THRESHOLD = 0.5\n",
    "\n",
    "  y_pred = tf.cast(y_pred > THRESHOLD, DTYPE) \n",
    "\n",
    "  true_positives = tf.math.count_nonzero(tf.math.logical_and(tf.math.equal(y_pred,1.0), tf.math.equal(y_true,1.0)), axis=0)\n",
    "  false_positives = tf.math.count_nonzero(tf.math.logical_and(tf.math.equal(y_pred,1.0), tf.math.equal(y_true,0.0)), axis=0)\n",
    "  false_negatives = tf.math.count_nonzero(tf.math.logical_and(tf.math.equal(y_pred,0.0), tf.math.equal(y_true,1.0)), axis=0)\n",
    "\n",
    "  TP = tf.math.reduce_sum(tf.cast(true_positives, DTYPE), axis=0)\n",
    "  FP = tf.math.reduce_sum(tf.cast(false_positives, DTYPE), axis=0)\n",
    "  FN = tf.math.reduce_sum(tf.cast(false_negatives, DTYPE), axis=0)\n",
    "\n",
    "  precision = tf.math.divide_no_nan(TP, TP+FP)\n",
    "  recall = tf.math.divide_no_nan(TP, TP+FN)\n",
    "\n",
    "  F1 = tf.math.divide_no_nan(2 * (precision * recall) , (precision + recall))\n",
    "  return F1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f9uJAWmXO6tE"
   },
   "source": [
    "### Using variational RNN\n",
    "* Same dropout mask accross the time steps using [RNNCellDropWrapper](https://www.tensorflow.org/api_docs/python/tf/nn/RNNCellDropoutWrapper)\n",
    "* [paper](https://arxiv.org/pdf/1512.05287.pdf)\n",
    "* [stack overflow](https://stackoverflow.com/questions/43950515/how-to-use-dropoutwrapper-in-lstm-training-and-decoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c-1bQebiPVjZ"
   },
   "outputs": [],
   "source": [
    "# Constrcut forward/backward LSTM cell with same dropout mask\n",
    "Forward = tf.keras.layers.GRU(256, dropout=0.5, name='forward')\n",
    "Backward = tf.keras.layers.GRU(256, dropout=0.5, go_backwards=True, name='backward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "X0VyBBv2Mim4",
    "outputId": "42d7c6ca-eb83-4044-b5ef-5ebed079ca01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_1 (Lambda)            (None, 256, 250)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (512, 512)                780288    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (512, 512)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (512, 6)                  3078      \n",
      "=================================================================\n",
      "Total params: 783,366\n",
      "Trainable params: 783,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# using Dropout and kernel_regularizer to prevent overfitting\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(MAX_LENGTH,),dtype=\"string\", batch_size=BATCH_SIZE),   \n",
    "    embed_layer,               \n",
    "    tf.keras.layers.Bidirectional(Forward, backward_layer=Backward, input_shape=(None, EMBED_SIZE),\n",
    "                         merge_mode='concat', dtype=tf.float32),\n",
    "    # tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32)),\n",
    "    # tf.keras.layers.Dense(64, activation='relu', dtype=tf.float32),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(6, activation='sigmoid', dtype=tf.float32)\n",
    "])\n",
    "#compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              metrics=[F1_score])\n",
    "\n",
    "# build the model to get the weight\n",
    "model.build((None,MAX_LENGTH))\n",
    "model.summary()\n",
    "# store the weight for later usage\n",
    "weights = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FWt4USucU_Cd"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6g9fsZbkU95I",
    "outputId": "ee9adcfc-2e3d-4f93-c929-ff9a70edea93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "69/69 [==============================] - 34s 499ms/step - loss: 0.4556 - F1_score: 0.0588 - val_loss: 0.0000e+00 - val_F1_score: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "69/69 [==============================] - 23s 328ms/step - loss: 0.3999 - F1_score: 0.3304 - val_loss: 0.3784 - val_F1_score: 0.3944\n",
      "Epoch 3/1000\n",
      "69/69 [==============================] - 23s 331ms/step - loss: 0.3822 - F1_score: 0.4250 - val_loss: 0.3684 - val_F1_score: 0.4505\n",
      "Epoch 4/1000\n",
      "69/69 [==============================] - 23s 328ms/step - loss: 0.3746 - F1_score: 0.4460 - val_loss: 0.3625 - val_F1_score: 0.4738\n",
      "Epoch 5/1000\n",
      "69/69 [==============================] - 23s 330ms/step - loss: 0.3687 - F1_score: 0.4639 - val_loss: 0.3610 - val_F1_score: 0.4622\n",
      "Epoch 6/1000\n",
      "69/69 [==============================] - 22s 325ms/step - loss: 0.3646 - F1_score: 0.4707 - val_loss: 0.3569 - val_F1_score: 0.4855\n",
      "Epoch 7/1000\n",
      "69/69 [==============================] - 22s 324ms/step - loss: 0.3609 - F1_score: 0.4810 - val_loss: 0.3517 - val_F1_score: 0.4960\n",
      "Epoch 8/1000\n",
      "69/69 [==============================] - 22s 324ms/step - loss: 0.3576 - F1_score: 0.4912 - val_loss: 0.3481 - val_F1_score: 0.5017\n",
      "Epoch 9/1000\n",
      "69/69 [==============================] - 22s 325ms/step - loss: 0.3551 - F1_score: 0.4984 - val_loss: 0.3467 - val_F1_score: 0.5149\n",
      "Epoch 10/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3526 - F1_score: 0.5047 - val_loss: 0.3456 - val_F1_score: 0.5159\n",
      "Epoch 11/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.3499 - F1_score: 0.5120 - val_loss: 0.3430 - val_F1_score: 0.5261\n",
      "Epoch 12/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.3475 - F1_score: 0.5180 - val_loss: 0.3397 - val_F1_score: 0.5281\n",
      "Epoch 13/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3452 - F1_score: 0.5222 - val_loss: 0.3389 - val_F1_score: 0.5341\n",
      "Epoch 14/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3436 - F1_score: 0.5276 - val_loss: 0.3368 - val_F1_score: 0.5415\n",
      "Epoch 15/1000\n",
      "69/69 [==============================] - 22s 325ms/step - loss: 0.3415 - F1_score: 0.5302 - val_loss: 0.3353 - val_F1_score: 0.5483\n",
      "Epoch 16/1000\n",
      "69/69 [==============================] - 23s 326ms/step - loss: 0.3404 - F1_score: 0.5356 - val_loss: 0.3333 - val_F1_score: 0.5485\n",
      "Epoch 17/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3374 - F1_score: 0.5431 - val_loss: 0.3323 - val_F1_score: 0.5586\n",
      "Epoch 18/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.3359 - F1_score: 0.5458 - val_loss: 0.3306 - val_F1_score: 0.5584\n",
      "Epoch 19/1000\n",
      "69/69 [==============================] - 23s 326ms/step - loss: 0.3348 - F1_score: 0.5482 - val_loss: 0.3304 - val_F1_score: 0.5579\n",
      "Epoch 20/1000\n",
      "69/69 [==============================] - 23s 326ms/step - loss: 0.3324 - F1_score: 0.5525 - val_loss: 0.3291 - val_F1_score: 0.5569\n",
      "Epoch 21/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3303 - F1_score: 0.5571 - val_loss: 0.3294 - val_F1_score: 0.5625\n",
      "Epoch 22/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3290 - F1_score: 0.5607 - val_loss: 0.3281 - val_F1_score: 0.5603\n",
      "Epoch 23/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.3272 - F1_score: 0.5643 - val_loss: 0.3269 - val_F1_score: 0.5708\n",
      "Epoch 24/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3255 - F1_score: 0.5680 - val_loss: 0.3270 - val_F1_score: 0.5720\n",
      "Epoch 25/1000\n",
      "69/69 [==============================] - 22s 323ms/step - loss: 0.3244 - F1_score: 0.5706 - val_loss: 0.3263 - val_F1_score: 0.5766\n",
      "Epoch 26/1000\n",
      "69/69 [==============================] - 22s 323ms/step - loss: 0.3220 - F1_score: 0.5741 - val_loss: 0.3258 - val_F1_score: 0.5757\n",
      "Epoch 27/1000\n",
      "69/69 [==============================] - 22s 324ms/step - loss: 0.3206 - F1_score: 0.5773 - val_loss: 0.3260 - val_F1_score: 0.5773\n",
      "Epoch 28/1000\n",
      "69/69 [==============================] - 23s 326ms/step - loss: 0.3191 - F1_score: 0.5826 - val_loss: 0.3251 - val_F1_score: 0.5845\n",
      "Epoch 29/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3165 - F1_score: 0.5850 - val_loss: 0.3250 - val_F1_score: 0.5773\n",
      "Epoch 30/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3164 - F1_score: 0.5869 - val_loss: 0.3239 - val_F1_score: 0.5802\n",
      "Epoch 31/1000\n",
      "69/69 [==============================] - 22s 325ms/step - loss: 0.3146 - F1_score: 0.5893 - val_loss: 0.3245 - val_F1_score: 0.5772\n",
      "Epoch 32/1000\n",
      "69/69 [==============================] - 23s 326ms/step - loss: 0.3117 - F1_score: 0.5950 - val_loss: 0.3244 - val_F1_score: 0.5789\n",
      "Epoch 33/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.3107 - F1_score: 0.5993 - val_loss: 0.3241 - val_F1_score: 0.5802\n",
      "Epoch 34/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.3081 - F1_score: 0.6034 - val_loss: 0.3277 - val_F1_score: 0.5840\n",
      "Epoch 35/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3064 - F1_score: 0.6060 - val_loss: 0.3262 - val_F1_score: 0.5747\n",
      "Epoch 36/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.3046 - F1_score: 0.6113 - val_loss: 0.3261 - val_F1_score: 0.5798\n",
      "Epoch 37/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.3020 - F1_score: 0.6137 - val_loss: 0.3244 - val_F1_score: 0.5871\n",
      "Epoch 38/1000\n",
      "69/69 [==============================] - 22s 325ms/step - loss: 0.3007 - F1_score: 0.6172 - val_loss: 0.3270 - val_F1_score: 0.5824\n",
      "Epoch 39/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.2972 - F1_score: 0.6253 - val_loss: 0.3267 - val_F1_score: 0.5769\n",
      "Epoch 40/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.2954 - F1_score: 0.6253 - val_loss: 0.3302 - val_F1_score: 0.5795\n",
      "Epoch 41/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.2939 - F1_score: 0.6303 - val_loss: 0.3306 - val_F1_score: 0.5725\n",
      "Epoch 42/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.2921 - F1_score: 0.6330 - val_loss: 0.3328 - val_F1_score: 0.5787\n",
      "Epoch 43/1000\n",
      "69/69 [==============================] - 23s 326ms/step - loss: 0.2891 - F1_score: 0.6375 - val_loss: 0.3311 - val_F1_score: 0.5718\n",
      "Epoch 44/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.2865 - F1_score: 0.6414 - val_loss: 0.3340 - val_F1_score: 0.5760\n",
      "Epoch 45/1000\n",
      "69/69 [==============================] - 22s 326ms/step - loss: 0.2843 - F1_score: 0.6469 - val_loss: 0.3406 - val_F1_score: 0.5716\n",
      "Epoch 46/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.2839 - F1_score: 0.6465 - val_loss: 0.3394 - val_F1_score: 0.5768\n",
      "Epoch 47/1000\n",
      "69/69 [==============================] - 23s 327ms/step - loss: 0.2811 - F1_score: 0.6524 - val_loss: 0.3416 - val_F1_score: 0.5726\n"
     ]
    }
   ],
   "source": [
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_F1_score',mode='max', patience=10)\n",
    "history = model.fit(train_dataset, epochs=1000, verbose=1,\n",
    "                    validation_data=val_dataset, \n",
    "                    callbacks = [earlystop],\n",
    "                    validation_steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FU7A5c0EDAG1"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "8rsoH8O6CwNm",
    "outputId": "6235cd16-9611-4e98-c84b-42ceae81a1e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11717, 6)\n",
      "[[0.53796464 0.42478228 0.52777076 0.5120058  0.4802838  0.6152423 ]\n",
      " [0.5076143  0.5007042  0.550709   0.5261106  0.42900875 0.5208264 ]\n",
      " [0.5185112  0.34719393 0.5887345  0.4804732  0.40590596 0.67691636]\n",
      " [0.5297364  0.40212327 0.5193733  0.51374394 0.52558    0.6285825 ]]\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(X_val.to_list())\n",
    "\n",
    "print(result.shape)\n",
    "print(result[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "1PzZ3dnQC_HX",
    "outputId": "c19d607f-1566-4230-888e-b3c836ac9edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11717, 6)\n",
      "(11717, 6)\n",
      "0.5690900337024555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "greater = (result>=0.5).astype(int)\n",
    "print(Y_val.shape)\n",
    "print(greater.shape)\n",
    "print(f1_score(Y_val, greater, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8tq1VnFpfihO"
   },
   "source": [
    "### Refit on the whole data with around 40 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eaIOyG1m-Qfm",
    "outputId": "4c1c7253-90d6-40a6-8752-6a50e8122b78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape:(46867,) and Label shape(46867, 6)\n"
     ]
    }
   ],
   "source": [
    "print('Training shape:{} and Label shape{}'. format(TRAIN.shape, LABEL.shape))\n",
    "# Build the dataset\n",
    "ALL_TRAIN_dataset = tf.data.Dataset.from_tensor_slices((TRAIN, LABEL.values))\n",
    "# shuffle, set batch and set prefetch\n",
    "ALL_TRAIN_dataset = ALL_TRAIN_dataset.shuffle(10000).batch(BATCH_SIZE)\n",
    "ALL_TRAIN_dataset = ALL_TRAIN_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_V88XxcllWik"
   },
   "outputs": [],
   "source": [
    "# reload the model weight\n",
    "model.set_weights(weights)\n",
    "# train with best epoch = 43\n",
    "history = model.fit(ALL_TRAIN_dataset, epochs=43, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4QooSTxfL24"
   },
   "source": [
    "##Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "httpAzgfsXFz"
   },
   "outputs": [],
   "source": [
    "TEST_DATA = pd.read_csv('./test_tokenize_nostem.csv')\n",
    "TEST = TEST_DATA['TOKEN'].apply(literal_eval) # convert to list (don't need this step if you use your own method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "vMP-c0bqfS1B",
    "outputId": "89c474f2-6f4a-4281-8ea7-ae00b2d02659"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131166,)\n",
      "['mobile', 'crowdsensing', 'is', 'a', 'promising', 'paradigm', 'for', 'ubiquitous', 'sensing', 'which', 'explores', 'the', 'tremendous', 'data', 'collected', 'by', 'mobile', 'smart', 'devices', 'with', 'prominent', 'spatial-temporal', 'coverage', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "# pad to same length\n",
    "for row in TEST:\n",
    "  if len(row) < MAX_LENGTH:\n",
    "    row.extend(['' for _ in range(MAX_LENGTH-len(row))])\n",
    "\n",
    "print(TEST.shape)\n",
    "print(TEST[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUMofd79s7Bn"
   },
   "outputs": [],
   "source": [
    "TEST_dataset = tf.data.Dataset.from_tensor_slices(TEST)\n",
    "TEST_dataset = TEST_dataset.batch(BATCH_SIZE)\n",
    "TEST_dataset = TEST_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "2MmqiA_ZmBcP",
    "outputId": "fdbb467a-479a-4438-e990-07702d40bf92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131166, 6)\n",
      "[[1.3198853e-03 5.6018233e-03 2.6428729e-02 8.2059246e-01 4.9370641e-01\n",
      "  2.4116337e-03]\n",
      " [9.9096978e-01 2.2083253e-02 7.5790286e-04 3.4436584e-04 2.1257997e-04\n",
      "  1.7622113e-04]\n",
      " [1.8643668e-01 5.8309507e-01 2.6996088e-01 1.3433120e-01 1.2393901e-01\n",
      "  3.6059946e-02]\n",
      " [1.4346242e-02 8.9676261e-02 4.6251270e-01 4.9801958e-01 1.5494758e-01\n",
      "  2.2586972e-02]]\n"
     ]
    }
   ],
   "source": [
    "TEST_RESULT = model.predict(TEST_dataset)\n",
    "\n",
    "print(TEST_RESULT.shape)\n",
    "print(TEST_RESULT[-5:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "dcqIg039-3v4",
    "outputId": "4b1e4e0c-c2d9-4644-aace-70f519a3d498"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BACKGROUND</th>\n",
       "      <th>OBJECTIVES</th>\n",
       "      <th>METHODS</th>\n",
       "      <th>RESULTS</th>\n",
       "      <th>CONCLUSIONS</th>\n",
       "      <th>OTHERS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946022</td>\n",
       "      <td>0.079508</td>\n",
       "      <td>0.003645</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.001954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743929</td>\n",
       "      <td>0.220450</td>\n",
       "      <td>0.032969</td>\n",
       "      <td>0.056480</td>\n",
       "      <td>0.041752</td>\n",
       "      <td>0.013041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.119440</td>\n",
       "      <td>0.380424</td>\n",
       "      <td>0.188641</td>\n",
       "      <td>0.174334</td>\n",
       "      <td>0.254004</td>\n",
       "      <td>0.075980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.036066</td>\n",
       "      <td>0.628425</td>\n",
       "      <td>0.392521</td>\n",
       "      <td>0.096206</td>\n",
       "      <td>0.042264</td>\n",
       "      <td>0.005441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.024162</td>\n",
       "      <td>0.192810</td>\n",
       "      <td>0.674457</td>\n",
       "      <td>0.322713</td>\n",
       "      <td>0.018350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BACKGROUND  OBJECTIVES   METHODS   RESULTS  CONCLUSIONS    OTHERS\n",
       "0    0.946022    0.079508  0.003645  0.001922     0.002508  0.001954\n",
       "1    0.743929    0.220450  0.032969  0.056480     0.041752  0.013041\n",
       "2    0.119440    0.380424  0.188641  0.174334     0.254004  0.075980\n",
       "3    0.036066    0.628425  0.392521  0.096206     0.042264  0.005441\n",
       "4    0.003079    0.024162  0.192810  0.674457     0.322713  0.018350"
      ]
     },
     "execution_count": 33,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RESULT = (TEST_RESULT>=0.5).astype(int)\n",
    "RESULT = pd.DataFrame(TEST_RESULT, columns=LABEL.columns)\n",
    "RESULT.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6nbr4YrsBtJY"
   },
   "outputs": [],
   "source": [
    "# save to csv file\n",
    "RESULT.to_csv('test_result.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "BidirectionalRNN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
